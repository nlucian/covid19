{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T19:04:13.839633Z",
     "start_time": "2020-05-06T19:04:10.648219Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import math\n",
    "import mplcyberpunk\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from urllib.request import urlopen\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# maps\n",
    "import folium\n",
    "import gmaps.geojson_geometries\n",
    "\n",
    "# cyberpunk custom styling\n",
    "import mplcyberpunk\n",
    "import matplotlib.ticker as ticker\n",
    "import seaborn as sns\n",
    "from matplotlib import animation as F\n",
    "from IPython.display import HTML, Image\n",
    "\n",
    "import plotly as py\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you wish to run this locally you will need the source file which can be found at <a href=\"https://github.com/nlucian/covid19/blob/master/BigDataProject_final.ipynb\" > github repo </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T19:19:40.347360Z",
     "start_time": "2020-05-02T19:19:40.343558Z"
    }
   },
   "source": [
    "### prerequisites  for running locally\n",
    "\n",
    "conda install -c conda-forge voila <br/>\n",
    "conda install folium -c conda-forge <br/>\n",
    "conda install -c conda-forge gmaps <br/>\n",
    "<br/>\n",
    "pip install mplcyberpunk\n",
    "conda update -all\n",
    "\n",
    "\n",
    "update all the project dependencies to the latest version\n",
    "\n",
    "### Folium\n",
    "##### Documentation\n",
    "https://python-visualization.github.io/folium/\n",
    "\n",
    "### Voila\n",
    "##### Documentation\n",
    "https://voila.readthedocs.io/en/latest/?badge=latest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pandas configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T19:04:13.846580Z",
     "start_time": "2020-05-06T19:04:13.841926Z"
    }
   },
   "outputs": [],
   "source": [
    "# pandas global configuration\n",
    "def set_pandas_display_options() -> None:\n",
    "    display = pd.options.display\n",
    "\n",
    "    display.max_columns = 100\n",
    "    display.max_rows = 500\n",
    "    display.max_colwidth = 200\n",
    "    display.width = None\n",
    "    # display.precision = 2  # set as needed\n",
    "\n",
    "set_pandas_display_options()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T19:04:13.852294Z",
     "start_time": "2020-05-06T19:04:13.849747Z"
    }
   },
   "outputs": [],
   "source": [
    "#utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T19:04:13.859993Z",
     "start_time": "2020-05-06T19:04:13.855810Z"
    }
   },
   "outputs": [],
   "source": [
    "# date is currently seen as string\n",
    "def StringisNaN(string):\n",
    "    return string != string\n",
    "\n",
    "# apply log to any number\n",
    "def apply_log(x):\n",
    "    if x != 0:\n",
    "        return np.log(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-03T14:48:58.613033Z",
     "start_time": "2020-05-03T14:48:58.601963Z"
    }
   },
   "source": [
    "<h4>We use the following data sources</h4>\n",
    "\n",
    "\n",
    "<ul>\n",
    "    <li><a href=\"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv\">covid confirmed cases</a></li>\n",
    "    <li><a href=\"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv\">covid deaths timeseries</a></li>\n",
    "    <li><a href=\"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_recovered_global.csv\">covid recovered cases</a></li>\n",
    "    <li><a href=\"https://raw.githubusercontent.com/nlucian/covid19/master/datasets/lockdown_country_dates.csv\"> covid lockdown dates</a></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T19:04:13.863794Z",
     "start_time": "2020-05-06T19:04:13.861637Z"
    }
   },
   "outputs": [],
   "source": [
    "# data loading and processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T19:04:14.951614Z",
     "start_time": "2020-05-06T19:04:13.866386Z"
    }
   },
   "outputs": [],
   "source": [
    "numbers_confirmed = pd.read_csv('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv')\n",
    "numbers_dead = pd.read_csv('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv')\n",
    "numbers_recovered = pd.read_csv('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_recovered_global.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### data cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T19:04:15.071859Z",
     "start_time": "2020-05-06T19:04:14.953803Z"
    }
   },
   "outputs": [],
   "source": [
    "missing_data_confirmedCases = numbers_confirmed.isnull()\n",
    "missing_data_confirmedCases.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T19:04:15.084102Z",
     "start_time": "2020-05-06T19:04:15.078933Z"
    }
   },
   "outputs": [],
   "source": [
    "#Count missing values in each column\n",
    "#False = not null, True = null\n",
    "# for column in missing_data_confirmedCases.columns:\n",
    "#     print(column)\n",
    "#     print(missing_data_confirmedCases[column].value_counts())\n",
    "#     print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Only the Province column contains nan values - 182 such values. Dropping the column seems like the best choice in this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T19:04:15.315938Z",
     "start_time": "2020-05-06T19:04:15.089315Z"
    }
   },
   "outputs": [],
   "source": [
    "lockdown_dates = pd.read_csv('https://raw.githubusercontent.com/nlucian/covid19/master/datasets/lockdown_country_dates.csv')\n",
    "lockdown_Romania=lockdown_dates.loc[lockdown_dates['Country/Region'] == 'Romania']\n",
    "\n",
    "lockdown_Romania.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T19:04:15.391264Z",
     "start_time": "2020-05-06T19:04:15.320414Z"
    }
   },
   "outputs": [],
   "source": [
    "# this part is unpivotting the table from the wide format to the long format\n",
    "confirmed_long = numbers_confirmed.melt(id_vars=[\"Province/State\", \"Country/Region\", \"Lat\", \"Long\"], var_name=\"Date\", value_name=\"Confirmed\").fillna('')\n",
    "dead_long = numbers_dead.melt(id_vars=[\"Province/State\", \"Country/Region\", \"Lat\", \"Long\"], var_name=\"Date\", value_name=\"Deaths\").fillna('')\n",
    "recovered_long = numbers_recovered.melt(id_vars=[\"Province/State\", \"Country/Region\", \"Lat\", \"Long\"], var_name=\"Date\", value_name=\"Recovered\").fillna('')\n",
    "\n",
    "confirmed_long.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T19:04:15.529706Z",
     "start_time": "2020-05-06T19:04:15.393493Z"
    }
   },
   "outputs": [],
   "source": [
    "# turn the 3 different tables into a single table with all the information, confirmed, dead and recovered\n",
    "\n",
    "daily_info = dead_long.merge(confirmed_long).merge(recovered_long).drop(['Lat', 'Long'], axis=1)\n",
    "daily_info.tail(5)\n",
    "\n",
    "daily_sum=daily_info.groupby(['Date'],as_index=True).sum()\n",
    "daily_sum.tail(5)\n",
    "\n",
    "#calculate daily values of deaths, confirmed and recovered \n",
    "daily_values=daily_sum.diff(periods=1)\n",
    "daily_values.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T19:04:15.559364Z",
     "start_time": "2020-05-06T19:04:15.532789Z"
    }
   },
   "outputs": [],
   "source": [
    "daily_info['Date'] = pd.to_datetime(daily_info['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T19:04:15.566901Z",
     "start_time": "2020-05-06T19:04:15.562140Z"
    }
   },
   "outputs": [],
   "source": [
    "# project constant values\n",
    "# the dataset is updated daily - we need the values of confirmed cases for the last date\n",
    "\n",
    "CONFIRMED_last_date = numbers_confirmed.columns.to_list()[-1]\n",
    "DEATHS_last_date    = numbers_dead.columns.to_list()[-1]\n",
    "RECOVERED_last_date = numbers_recovered.columns.to_list()[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T19:04:15.579410Z",
     "start_time": "2020-05-06T19:04:15.569638Z"
    }
   },
   "outputs": [],
   "source": [
    "# data preparation for maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T19:04:15.592014Z",
     "start_time": "2020-05-06T19:04:15.582264Z"
    }
   },
   "outputs": [],
   "source": [
    "# we only need the country and the total cases for now\n",
    "df1 = numbers_confirmed.loc[:,'Province/State' : 'Long']\n",
    "df2 = numbers_confirmed.iloc[:,-1]\n",
    "\n",
    "frames = [df1, df2]\n",
    "\n",
    "confirmed_cases_temp = pd.concat(frames, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T19:04:15.606775Z",
     "start_time": "2020-05-06T19:04:15.596191Z"
    }
   },
   "outputs": [],
   "source": [
    "confirmed_cases = confirmed_cases_temp.groupby(['Country/Region'], as_index=False)[CONFIRMED_last_date].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T19:04:15.642457Z",
     "start_time": "2020-05-06T19:04:15.609904Z"
    }
   },
   "outputs": [],
   "source": [
    "array_of_provinces = {'Denmark': 'Greenland'}\n",
    "\n",
    "# we want to define some provinces as individual countries\n",
    "# since we already do a group by we also have to subtract the number of cases from the group by reuslts\n",
    "def keep_provinces_as_countries(provinces, df_before_grp_by, df_after_grp_by, last_column_date_string):\n",
    "    for country in provinces:\n",
    "        print(\"For country '{}' defining its province '{}' as a country.\".format(country, provinces.get(country)))\n",
    "        province_cases = df_before_grp_by[df_before_grp_by['Province/State'] == provinces.get(country)][last_column_date_string]\n",
    "        \n",
    "        province_cases_value = province_cases.to_list()[0]\n",
    "        print(\"Province_cases {}\".format(province_cases_value))\n",
    "        \n",
    "        to_subtract_from = df_after_grp_by.loc[df_after_grp_by['Country/Region'] == country, [last_column_date_string]][last_column_date_string].to_list()[0]\n",
    "        print(\"value after group by {}\".format(to_subtract_from))\n",
    "        \n",
    "        final_value = to_subtract_from - province_cases_value\n",
    "        print(\"Province cases final value {}\".format(final_value))\n",
    "        \n",
    "        df_after_grp_by.loc[df_after_grp_by['Country/Region'] == country ,[last_column_date_string]]  = final_value\n",
    "        \n",
    "        print(\"Appending country {} with cases {}\".format(provinces.get(country), province_cases_value))\n",
    "        return df_after_grp_by.append({'Country/Region' : provinces.get(country), str(CONFIRMED_last_date) : province_cases_value}, ignore_index=True)\n",
    "    \n",
    "confirmed_cases = keep_provinces_as_countries(array_of_provinces, confirmed_cases_temp, confirmed_cases, CONFIRMED_last_date)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T19:04:15.652630Z",
     "start_time": "2020-05-06T19:04:15.646505Z"
    }
   },
   "outputs": [],
   "source": [
    "confirmed_cases = confirmed_cases.rename(columns = {'Country/Region': 'country', CONFIRMED_last_date: 'covid_cases'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T19:04:15.668604Z",
     "start_time": "2020-05-06T19:04:15.658853Z"
    }
   },
   "outputs": [],
   "source": [
    "confirmed_cases = confirmed_cases.sort_values(by = ['covid_cases'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T19:04:17.918313Z",
     "start_time": "2020-05-06T19:04:15.683328Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load GeoJSON of countries\n",
    "countries_geojson = gmaps.geojson_geometries.load_geometry('countries') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T19:04:17.925392Z",
     "start_time": "2020-05-06T19:04:17.921049Z"
    }
   },
   "outputs": [],
   "source": [
    "dict_confirmed_cases = pd.Series(confirmed_cases.covid_cases.values, index=confirmed_cases.country).to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### update keys to match the geojson namings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The left-hand side is the gmaps definition of countries which must be mapped to the github source of covid cases per country.\n",
    "\n",
    "There are 3 cases:\n",
    "\n",
    "There is either no  mapping at all since the github repo does not track the number of cases for the given country;\n",
    "There is a name mismatching  which must be corrected;\n",
    "The region/country in gmaps is part of a country so we cumulate the cases under the mother country;\n",
    "\n",
    "eg.  if the name is wrong -> replacement of the github country name with the gmaps naming;\n",
    "eg.  if some islands like Cayman Islands are owned by UK we display it under UK;\n",
    "eg. no country present in github from the gmap list (since we iterate through all the countries, we just ignore it)\n",
    "\n",
    "<ul>\n",
    "    <li>Aland -> not found</li>\n",
    "    <li>America Samoa ->  not found</li>\n",
    "    <li>Antarctica -> not found</li>\n",
    "    <li>French Southern and Antarctic Lands -> not found</li>\n",
    "    <li>Northern Cyprus -> Cyprus</li>\n",
    "    <li>Cayman Islands -> UK</li>\n",
    "    <li>Curacao -> Netherlands</li>\n",
    "    <li>The Bahamas -> Bahamas</li>\n",
    "    <li>Repubulc of Congo -> Congo (Brazzavilli)</li>\n",
    "    <li>Democratic Repubulc of the Congo -> Congo (Kinshasa)</li>\n",
    "    <li>Comoros -> not found</li>\n",
    "    <li>Cape Verde -> Cabo Verde</li>\n",
    "    <li>CuraÃ§ao -> Netherlands</li>\n",
    "    <li>Cayman Islands -> UK</li>\n",
    "    <li>Falkland Islands -> UK</li>\n",
    "    <li>Faroe Islands -> Denmark</li>\n",
    "    <li>Federated States of Micronesia -> not found</li>\n",
    "    <li>Guinea-Bissau -> Guinea Bissau</li>\n",
    "    <li>Hong Kong S.A.R -> China</li>\n",
    "    <li>Isli of Man -> UK</li>\n",
    "    <li>Baykonur Cosmodrome -> not found</li>\n",
    "    <li>Siachen Glacier -> not found</li>\n",
    "    <li>South Korea -> Korea, South</li>\n",
    "    <li>Lesotho -> not found</li>\n",
    "    <li>North Macedonia -> Macedonia</li>\n",
    "    <li>Myanmar -> Burma</li>\n",
    "    <li>Northern Mariana Islands -> not found</li>\n",
    "    <li>New Calidonia -> France</li>\n",
    "    <li>Niue -> not found</li>\n",
    "    <li>Palau -> not found</li>\n",
    "    <li>North Korea -> Kim Jong is hiding these days </li>\n",
    "    <li>Palistine -> not found</li>\n",
    "    <li>French Polynesia -> France</li>\n",
    "    <li>Solomon Islands -> not found</li>\n",
    "    <li>Saint helina -> not found</li>\n",
    "    <li>South Georgia and South Sandwich Islands -> not found</li>\n",
    "    <li>Somaulland -> not found</li>\n",
    "    <li>Saint Pierre and Miquelon,France -> France</li>\n",
    "    <li>Repubulc of Serbia -> Serbia</li>\n",
    "    <li>Swaziland -> not found</li>\n",
    "    <li>Tajikistan -> not found</li>\n",
    "    <li>East Timor -> Timor-Leste</li>\n",
    "    <li>Turkmenistan -> not found</li>\n",
    "    <li>Taiwan -> Taiwan*</li>\n",
    "    <li>United States Virgin Islands-> UK</li>\n",
    "    <li>Samoa -> not found</li>\n",
    "    <li>Yemen -> not found</li>\n",
    "    \n",
    "<ul/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T19:04:17.931073Z",
     "start_time": "2020-05-06T19:04:17.927526Z"
    }
   },
   "outputs": [],
   "source": [
    "def replace_country_key(old_key, new_key, dictionary):\n",
    "    try:\n",
    "        dictionary[new_key] = dictionary[old_key]\n",
    "        del dict_confirmed_cases[old_key]\n",
    "    except Exception as e:\n",
    "        print(\"Error while mapping country {} or country already mapped.\".format(str(e)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T19:04:17.947771Z",
     "start_time": "2020-05-06T19:04:17.941715Z"
    }
   },
   "outputs": [],
   "source": [
    "# name mapping error\n",
    "replace_country_key('US', 'United States of America', dict_confirmed_cases)\n",
    "replace_country_key('Bahamas', 'The Bahamas', dict_confirmed_cases)\n",
    "replace_country_key('Czechia', 'Czech Republic', dict_confirmed_cases)\n",
    "\n",
    "replace_country_key('Congo (Brazzaville)', 'Republic of Congo', dict_confirmed_cases)\n",
    "replace_country_key('Congo (Kinshasa)', 'Democratic Republic of the Congo', dict_confirmed_cases)\n",
    "\n",
    "replace_country_key('Cabo Verde', 'Cape Verde', dict_confirmed_cases)\n",
    "replace_country_key('Guinea-Bissau', 'Guinea Bissau', dict_confirmed_cases)\n",
    "replace_country_key('Korea, South', 'South Korea', dict_confirmed_cases)\n",
    "replace_country_key('North Macedonia', 'Macedonia', dict_confirmed_cases)\n",
    "replace_country_key('Burma','Myanmar', dict_confirmed_cases)\n",
    "replace_country_key('Serbia', 'Republic of Serbia', dict_confirmed_cases)\n",
    "replace_country_key('Timor-Leste', 'East Timor', dict_confirmed_cases)\n",
    "replace_country_key('Taiwan*', 'Taiwan', dict_confirmed_cases)\n",
    "replace_country_key('Tanzania', 'United Republic of Tanzania', dict_confirmed_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T19:04:17.955510Z",
     "start_time": "2020-05-06T19:04:17.952187Z"
    }
   },
   "outputs": [],
   "source": [
    "# custom data for some of the next map trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T19:04:17.965011Z",
     "start_time": "2020-05-06T19:04:17.959388Z"
    }
   },
   "outputs": [],
   "source": [
    "dict_confirmed_cases\n",
    "dict_confirmed_cases_df = pd.DataFrame(list(dict_confirmed_cases.items()), \n",
    "                                       columns = ['countries','covid_cases']) \n",
    "\n",
    "dict_confirmed_cases_df['countries'] = dict_confirmed_cases_df['countries'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAPS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Worldmap with total COVID-19 cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### select the color you wish to generate the map with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T19:04:17.973955Z",
     "start_time": "2020-05-06T19:04:17.967396Z"
    }
   },
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T19:04:17.992603Z",
     "start_time": "2020-05-06T19:04:17.977185Z"
    }
   },
   "outputs": [],
   "source": [
    "dict_confirmed_cases_df['covid_cases'] =  dict_confirmed_cases_df['covid_cases'].astype(int)\n",
    "dict_confirmed_cases_df['covid_cases'] =  dict_confirmed_cases_df['covid_cases'].apply(apply_log)\n",
    "\n",
    "\n",
    "print(dict_confirmed_cases_df['covid_cases'].min())\n",
    "print(dict_confirmed_cases_df['covid_cases'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T19:04:18.007484Z",
     "start_time": "2020-05-06T19:04:17.996295Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_covid_map(fill_color):\n",
    "\n",
    "    legend_name = 'COVID-19 cases worldwide'\n",
    "    m3 = folium.Map(location=[51.505, -0.09], tiles='cartodbpositron', max_bounds=True,\n",
    "                   zoom_start=1.5, min_zoom = 2)\n",
    "\n",
    "    folium.Choropleth(\n",
    "        geo_data=countries_geojson,\n",
    "        data=dict_confirmed_cases_df,\n",
    "        fill_color=fill_color,\n",
    "        legend_named='COVID-19 cases worldwide (log scale)',\n",
    "        columns=['countries', 'covid_cases'],\n",
    "        key_on='feature.properties.name',\n",
    "        fill_opacity=0.9,\n",
    "        line_opacity=0.1,\n",
    "        nan_fill_color='ffffff'\n",
    "    ).add_to(m3)\n",
    "    \n",
    "    display(m3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T19:04:18.020122Z",
     "start_time": "2020-05-06T19:04:18.010080Z"
    }
   },
   "outputs": [],
   "source": [
    "map_output_widget = widgets.Output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T19:04:18.038160Z",
     "start_time": "2020-05-06T19:04:18.024447Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "map_colors =  {'Green':'BuGn', 'Red':'RdPu'}\n",
    "\n",
    "select_variable = widgets.Dropdown(\n",
    "    options=map_colors,\n",
    "    value=map_colors.get('Blue'),\n",
    "    description='Colors'\n",
    ")\n",
    "\n",
    "def get_and_plot(b):\n",
    "    with map_output_widget:\n",
    "        clear_output()\n",
    "        print(select_variable.value)\n",
    "        generate_covid_map(select_variable.value)\n",
    "        \n",
    "select_variable.observe(get_and_plot, names='value')\n",
    "\n",
    "display(select_variable)\n",
    "display(map_output_widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Worldmap with COVID-19 mortality \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T19:04:18.044540Z",
     "start_time": "2020-05-06T19:04:18.040439Z"
    }
   },
   "outputs": [],
   "source": [
    "modified_deaths = numbers_dead[numbers_dead[DEATHS_last_date] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Density Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T19:04:18.505191Z",
     "start_time": "2020-05-06T19:04:18.046893Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(24,8))\n",
    "plt.subplot(1,2,1)\n",
    "(modified_deaths[DEATHS_last_date]).plot.kde()\n",
    "plt.subplot(1,2,2)\n",
    "(np.log10(modified_deaths[DEATHS_last_date])).plot.kde()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If we use the original values, then we won't be able to distinguish the colors of the map (that's why we are going apply $log_{10}$ since the values are more spread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T19:04:18.511572Z",
     "start_time": "2020-05-06T19:04:18.507049Z"
    }
   },
   "outputs": [],
   "source": [
    "modified_deaths['Transformed_value'] = np.log10(modified_deaths[DEATHS_last_date])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T19:04:18.527712Z",
     "start_time": "2020-05-06T19:04:18.514018Z"
    }
   },
   "outputs": [],
   "source": [
    "df_new = pd.DataFrame(columns = ['Country', 'Date', 'Confirmed', 'Recovered', 'Dead', 'Transformed_value'])    \n",
    "\n",
    "df_new['Country'] = modified_deaths['Country/Region']\n",
    "df_new['Date'] = CONFIRMED_last_date\n",
    "df_new['Confirmed'] = numbers_confirmed[CONFIRMED_last_date]\n",
    "df_new['Dead'] = numbers_dead[DEATHS_last_date]\n",
    "df_new['Recovered'] = numbers_recovered[RECOVERED_last_date]\n",
    "df_new['Transformed_value'] = modified_deaths['Transformed_value']\n",
    "df_new = df_new[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T19:04:19.317852Z",
     "start_time": "2020-05-06T19:04:18.530578Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = px.choropleth(\n",
    "    df_new,\n",
    "    locations = 'Country',\n",
    "    locationmode = 'country names',\n",
    "    color = 'Transformed_value',\n",
    "    hover_name = 'Country',\n",
    "    hover_data = ['Confirmed','Recovered','Dead'], \n",
    "    animation_frame= 'Date',\n",
    "    color_continuous_scale=px.colors.diverging.RdYlGn[::-1]\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text =   \" COVID-19 Spread in the World up to \" + DEATHS_last_date,\n",
    "    title_x = 0.5,\n",
    "    geo= dict(\n",
    "        showframe= False,\n",
    "        showcoastlines= False,\n",
    "        projection_type = 'equirectangular'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### healed vs deaths percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T19:04:19.399007Z",
     "start_time": "2020-05-06T19:04:19.320251Z"
    }
   },
   "outputs": [],
   "source": [
    "# turn the 3 different tables into a single table with all the information, confirmed, dead and recovered\n",
    "daily_info = dead_long.merge(confirmed_long).merge(recovered_long).drop(['Lat', 'Long'], axis=1)\n",
    "daily_sum  = daily_info.groupby(['Date'],as_index=True).sum()\n",
    "\n",
    "#calculate daily values of deaths, confirmed and recovered \n",
    "daily_values = daily_sum.diff(periods=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T19:04:19.412448Z",
     "start_time": "2020-05-06T19:04:19.400602Z"
    }
   },
   "outputs": [],
   "source": [
    "daily_sum['death_percentage'] = daily_sum['Deaths']/daily_sum['Confirmed'] *100\n",
    "daily_sum['heal_percentage']  = daily_sum['Recovered']/daily_sum['Confirmed'] *100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T19:04:19.418427Z",
     "start_time": "2020-05-06T19:04:19.414409Z"
    }
   },
   "outputs": [],
   "source": [
    "daily_sum.reset_index(level=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T19:04:20.300230Z",
     "start_time": "2020-05-06T19:04:19.420265Z"
    }
   },
   "outputs": [],
   "source": [
    "def plotHealDeathPercentage():   \n",
    "        plt.style.use(\"cyberpunk\")\n",
    "        fig = plt.figure(figsize=(20,10))\n",
    "        \n",
    "        plt.locator_params(axis='x', nbins=15)\n",
    "        \n",
    "        plt.plot(daily_sum['Date'], daily_sum['death_percentage'], label = 'Death Percentage')\n",
    "        plt.plot(daily_sum['Date'], daily_sum['heal_percentage'], label = 'Heal Percentage')\n",
    "        \n",
    "        plt.legend(loc=2, prop={'size': 18})\n",
    "        plt.xticks(rotation=90, ha='right', fontsize=\"x-large\")\n",
    "        plt.yticks(fontsize=\"x-large\")\n",
    "        \n",
    "        ax = plt.gca()\n",
    "        temp = ax.xaxis.get_ticklabels()\n",
    "        temp = list(set(temp) - set(temp[::3]))\n",
    "        for label in temp:\n",
    "            label.set_visible(False)\n",
    "        \n",
    "        \n",
    "        mplcyberpunk.make_lines_glow(ax)\n",
    "\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "plotHealDeathPercentage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Countries Investigated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T19:04:20.306409Z",
     "start_time": "2020-05-06T19:04:20.302111Z"
    }
   },
   "outputs": [],
   "source": [
    "# data modeling for the investigated countries plot\n",
    "\n",
    "def dataFrameForCountry(country):\n",
    "    country_data=daily_info.loc[daily_info['Country/Region'] == country]\n",
    "    country_data=country_data.drop([\"Province/State\",\"Country/Region\"], axis=1)\n",
    "    country_data.set_index('Date', inplace = True) \n",
    "\n",
    "    country_data_daily = country_data.diff(periods=1)\n",
    "    country_data_daily = country_data_daily[(country_data_daily > 0).any(axis=1)]\n",
    "\n",
    "    country_data_daily['DateOf'] = country_data_daily.index\n",
    "    return country_data_daily\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T19:04:20.332785Z",
     "start_time": "2020-05-06T19:04:20.308647Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "countries_Investigated = ['Romania', 'Italy', 'Sweden', 'Belarus','Iran','Belgium', 'Poland','Germany', 'Brazil','Mexico','Russia','Turkey','Indonesia','Egypt','Portugal','Ukraine','Pakistan','Hungary']\n",
    "select_countries = widgets.Dropdown(\n",
    "    options=countries_Investigated,\n",
    "    value=countries_Investigated[0],\n",
    "    description='Countries'\n",
    ")\n",
    "\n",
    "ci_output = widgets.Output()\n",
    "display(widgets.VBox([ci_output, select_countries]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T19:04:20.482713Z",
     "start_time": "2020-05-06T19:04:20.335334Z"
    }
   },
   "outputs": [],
   "source": [
    "@ci_output.capture()\n",
    "def RestrictionsEffectForCountry(country):\n",
    "    plt.style.use(\"cyberpunk\")\n",
    "    \n",
    "    dataFrame = dataFrameForCountry(country)\n",
    "    \n",
    "    dataFrame.plot(y=['Confirmed','Deaths','Recovered'],kind='bar',figsize=(20,10),color=['orange','darkred','lightgreen'])\n",
    "\n",
    "\n",
    "    lockdown_date_type=lockdown_dates.loc[lockdown_dates['Country/Region'] == country]\n",
    "  \n",
    "    if(not(StringisNaN(lockdown_date_type.iloc[0]['Date']))):\n",
    "        date_format = \"%Y-%m-%d\"\n",
    "        \n",
    "        first_lockdown_measure=datetime.strptime(lockdown_date_type.iloc[0]['Date'],date_format)\n",
    "        first_case_date=datetime.strptime(str(dataFrame.iloc[0]['DateOf']),'%m/%d/%y')\n",
    "        delta = first_lockdown_measure - first_case_date\n",
    "        plt.axvspan(0, delta.days, facecolor='#FFFF33', alpha=0.5,zorder=0.1)\n",
    "        plt.axvspan(delta.days, len(dataFrame.index), facecolor='green', alpha=0.5,zorder=0.1)\n",
    "        plt.suptitle(country+' (quarantine started on '+ first_lockdown_measure.strftime(\"%Y-%m-%d\")+')', fontsize=15)\n",
    "    else:\n",
    "        plt.suptitle(country+' (no quarantine)', fontsize=15)\n",
    "    plt.legend(loc=1, prop={'size': 15})\n",
    "    ax = plt.gca()\n",
    "    temp = ax.xaxis.get_ticklabels()\n",
    "    temp = list(set(temp) - set(temp[::3]))\n",
    "    for label in temp:\n",
    "        label.set_visible(False)\n",
    "    x_axis = ax.axes.get_xaxis()\n",
    "    x_axis.set_label_text('')\n",
    "    ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "    ax.tick_params(axis='both', which='minor', labelsize=15)\n",
    "    mplcyberpunk.make_lines_glow(ax)    \n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T19:04:20.490455Z",
     "start_time": "2020-05-06T19:04:20.485285Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_investigated_countries(a):\n",
    "    with ci_output:\n",
    "        clear_output()\n",
    "        print(select_countries.value)\n",
    "        RestrictionsEffectForCountry(select_countries.value)\n",
    "\n",
    "select_countries.observe(plot_investigated_countries, names='value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T19:04:20.498023Z",
     "start_time": "2020-05-06T19:04:20.492794Z"
    }
   },
   "outputs": [],
   "source": [
    "CONFIRMED_last_date #CONFIRMED_last_date = numbers_confirmed.columns.to_list()[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T19:04:20.507226Z",
     "start_time": "2020-05-06T19:04:20.501488Z"
    }
   },
   "outputs": [],
   "source": [
    "total_confirmed_case = numbers_confirmed[CONFIRMED_last_date].sum()\n",
    "print(f\"{total_confirmed_case:,} confirmed cases\")\n",
    "\n",
    "total_recovered_cases = numbers_recovered[RECOVERED_last_date].sum()\n",
    "print(f\"{total_recovered_cases:,} recovered\")\n",
    "\n",
    "total_deaths = numbers_dead[RECOVERED_last_date].sum()\n",
    "print(f\"{total_deaths:,} deaths\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T19:04:20.521529Z",
     "start_time": "2020-05-06T19:04:20.515550Z"
    }
   },
   "outputs": [],
   "source": [
    "top_ten = numbers_confirmed.sort_values(by = CONFIRMED_last_date  , ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T19:04:20.591975Z",
     "start_time": "2020-05-06T19:04:20.524128Z"
    }
   },
   "outputs": [],
   "source": [
    "top_ten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 10 countries with COVID-19 confirmed cases - last date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T19:04:20.887475Z",
     "start_time": "2020-05-06T19:04:20.594681Z"
    }
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(12,8))\n",
    "\n",
    "#plt.figure(figsize=(12,8))\n",
    "ax = sns.barplot(x = CONFIRMED_last_date, y = 'Country/Region', \n",
    "              data = top_ten)\n",
    "ax.set(xlabel='Confirmed Cases', ylabel='Country')\n",
    "\n",
    "for i, (value, name) in enumerate(zip(top_ten[CONFIRMED_last_date], top_ten['Country/Region'])):\n",
    "    ax.text(value, i-0.20,     value,           ha='right')\n",
    "    \n",
    "ax.text(1, 0.4, CONFIRMED_last_date, transform=ax.transAxes, size=46, ha='right')\n",
    "\n",
    "plt.title(\"Top ten countries with confirmed covid cases\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T19:04:20.909049Z",
     "start_time": "2020-05-06T19:04:20.889939Z"
    }
   },
   "outputs": [],
   "source": [
    "nrc_grouped_by_country = numbers_confirmed.groupby(['Country/Region'], as_index=False).sum()\n",
    "nrd_grouped_by_country = numbers_dead.groupby(['Country/Region'], as_index=False).sum()\n",
    "nr_grouped_By_country = numbers_recovered.groupby(['Country/Region'], as_index=False).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Animated barcharts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T19:04:20.942571Z",
     "start_time": "2020-05-06T19:04:20.912471Z"
    }
   },
   "outputs": [],
   "source": [
    "global category\n",
    "\n",
    "category = 'Dead'\n",
    "\n",
    "def draw_barchart(date):\n",
    "    \n",
    "    \n",
    "    if category == 'Confirmed':\n",
    "        df_top10 = (nrc_grouped_by_country.sort_values(by=date,ascending=False).head(10))\n",
    "    elif category == 'Dead':\n",
    "        df_top10 = (nrd_grouped_by_country.sort_values(by=date,ascending=False).head(10))\n",
    "    elif category == 'Recovered':\n",
    "        df_top10 = (nr_grouped_By_country.sort_values(by=date,ascending=False).head(10))\n",
    "    else:\n",
    "        return\n",
    "\n",
    "    df_new = pd.DataFrame(columns = ['Country', 'Date', category])    \n",
    "    \n",
    "    df_new['Country'] = df_top10['Country/Region']\n",
    "    df_new['Date'] = date\n",
    "    df_new[category] = df_top10[date]\n",
    "    df_new = df_new[::-1]\n",
    "    \n",
    "    ax.clear()\n",
    "    \n",
    "    ax.barh(df_new['Country'], df_new[category], color=[\"#980505\",\"#CD1212\",\"#D84E4E\",\"#CB6262\",\"#D39B5F\",\"#F7EC10\",\"#D0F710\",\"#9CF710\",\"#B4D67F\",\"#969C8E\"])\n",
    "    \n",
    "\n",
    "    dx = df_new[category].max() / 200\n",
    "    \n",
    "    \n",
    "    for i, (value, name) in enumerate(zip(df_new[category], df_new['Country'])):\n",
    "        ax.text(value-dx, i,     name,           size=14, weight=600, ha='right', va='bottom')\n",
    "        ax.text(value+dx, i-.15, value, size=13, color='k', ha='left', va='center')\n",
    "        \n",
    "        \n",
    "        \n",
    "    ax.text(1, 0.4, date, transform=ax.transAxes, color='#777777', size=30, ha='right', weight=800)\n",
    "    ax.text(0, 1.06, 'Number of Cases', transform=ax.transAxes, size=12, color='#777777')\n",
    "    ax.xaxis.set_major_formatter(ticker.StrMethodFormatter('{x:,.0f}'))\n",
    "    ax.xaxis.set_ticks_position('top')\n",
    "    ax.tick_params(axis='x', colors='#777777', labelsize=12)\n",
    "    ax.set_yticks([])\n",
    "    ax.margins(0, 0.01)\n",
    "    ax.grid(which='major', axis='x', linestyle='-')\n",
    "    ax.set_axisbelow(True)\n",
    "    ax.text(0, 1.1, 'The number of ' + category + ' cases up to ' + CONFIRMED_last_date,\n",
    "            transform=ax.transAxes, size=24, weight=600, ha='left')\n",
    "    ax.text(1, 0, 'credit @jburnmurdoch', transform=ax.transAxes, ha='right',\n",
    "            color='#777777', bbox=dict(facecolor='white', alpha=0.8, edgecolor='white'))\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T19:04:20.955978Z",
     "start_time": "2020-05-06T19:04:20.945925Z"
    }
   },
   "outputs": [],
   "source": [
    "#animator = F.FuncAnimation(fig,draw_barchart,frames = numbers_confirmed.columns[3:], interval = 150, repeat = True)\n",
    "#HTML(animator.to_jshtml())\n",
    "#animator.save(r'saved_gifs\\animation_dead.gif', writer='imagemagick', fps=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T19:04:21.090914Z",
     "start_time": "2020-05-06T19:04:20.958975Z"
    }
   },
   "outputs": [],
   "source": [
    "Image('animation_dead.gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T19:04:21.262466Z",
     "start_time": "2020-05-06T19:04:21.093648Z"
    }
   },
   "outputs": [],
   "source": [
    "Image('animation_recovered.gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T19:04:21.497935Z",
     "start_time": "2020-05-06T19:04:21.269774Z"
    }
   },
   "outputs": [],
   "source": [
    "Image('animation_confirmed.gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
