{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sys\n",
    "import math\n",
    "import copy\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import math\n",
    "import mplcyberpunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from urllib.request import urlopen\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maps\n",
    "import folium\n",
    "import gmaps.geojson_geometries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# styyle/display stuff\n",
    "from IPython.display import Markdown as md\n",
    "import mplcyberpunk\n",
    "import matplotlib.ticker as ticker\n",
    "import seaborn as sns\n",
    "from matplotlib import animation as F\n",
    "from IPython.display import HTML, Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.svm import SVR\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Input, Bidirectional\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly as py\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score\n",
    "from sklearn.metrics import mean_squared_error, r2_score, make_scorer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:55:05.463971Z",
     "start_time": "2020-05-23T19:55:05.436056Z"
    }
   },
   "outputs": [],
   "source": [
    "# scaling & normalization\n",
    "from sklearn.preprocessing import Normalizer, PolynomialFeatures, MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you wish to run this locally you will need the source file which can be found at <a href=\"https://github.com/nlucian/covid19/blob/master/BigDataProject_final.ipynb\" > github repo </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-02T19:19:40.347360Z",
     "start_time": "2020-05-02T19:19:40.343558Z"
    }
   },
   "source": [
    "### prerequisites  for running locally\n",
    "\n",
    "conda install -c conda-forge voila <br/>\n",
    "conda install folium -c conda-forge <br/>\n",
    "conda install -c conda-forge gmaps <br/>\n",
    "<br/>\n",
    "pip install mplcyberpunk\n",
    "conda update -all\n",
    "\n",
    "\n",
    "update all the project dependencies to the latest version\n",
    "\n",
    "### Folium\n",
    "##### Documentation\n",
    "https://python-visualization.github.io/folium/\n",
    "\n",
    "### Voila\n",
    "##### Documentation\n",
    "https://voila.readthedocs.io/en/latest/?badge=latest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pandas configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:44.461244Z",
     "start_time": "2020-05-23T19:31:44.456370Z"
    }
   },
   "outputs": [],
   "source": [
    "# pandas global configuration\n",
    "def set_pandas_display_options() -> None:\n",
    "    display = pd.options.display\n",
    "\n",
    "    display.max_columns = 100\n",
    "    display.max_rows = 500\n",
    "    display.max_colwidth = 200\n",
    "    display.width = None\n",
    "    # display.precision = 2  # set as needed\n",
    "\n",
    "set_pandas_display_options()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:44.467177Z",
     "start_time": "2020-05-23T19:31:44.463665Z"
    }
   },
   "outputs": [],
   "source": [
    "#utility functions\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "\n",
    "def applyStandardScaler(values):\n",
    "    scaler = Normalizer()\n",
    "    scaled_result = scaler.fit_transform(values)\n",
    "    return scaled_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:44.472542Z",
     "start_time": "2020-05-23T19:31:44.469375Z"
    }
   },
   "outputs": [],
   "source": [
    "# date is currently seen as string\n",
    "def StringisNaN(string):\n",
    "    return string != string\n",
    "\n",
    "# apply log to any number\n",
    "def apply_log(x):\n",
    "    if x != 0:\n",
    "        return np.log(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-03T14:48:58.613033Z",
     "start_time": "2020-05-03T14:48:58.601963Z"
    }
   },
   "source": [
    "<h4>We use the following data sources</h4>\n",
    "\n",
    "\n",
    "<ul>\n",
    "    <li><a href=\"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv\">covid confirmed cases</a></li>\n",
    "    <li><a href=\"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv\">covid deaths timeseries</a></li>\n",
    "    <li><a href=\"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_recovered_global.csv\">covid recovered cases</a></li>\n",
    "    <li><a href=\"https://raw.githubusercontent.com/nlucian/covid19/master/datasets/lockdown_country_dates.csv\"> covid lockdown dates</a></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:44.476287Z",
     "start_time": "2020-05-23T19:31:44.474305Z"
    }
   },
   "outputs": [],
   "source": [
    "# data loading and processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:45.541520Z",
     "start_time": "2020-05-23T19:31:44.477870Z"
    }
   },
   "outputs": [],
   "source": [
    "numbers_confirmed = pd.read_csv('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv')\n",
    "numbers_dead = pd.read_csv('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv')\n",
    "numbers_recovered = pd.read_csv('https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_recovered_global.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:45.548092Z",
     "start_time": "2020-05-23T19:31:45.544558Z"
    }
   },
   "outputs": [],
   "source": [
    "# uncomment if you wish to view the rows with misssing values\n",
    "# missing_data_confirmedCases = numbers_confirmed.isnull()\n",
    "# missing_data_confirmedCases.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Only the Province column contains nan values - 182 such values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:45.750231Z",
     "start_time": "2020-05-23T19:31:45.552578Z"
    }
   },
   "outputs": [],
   "source": [
    "lockdown_dates = pd.read_csv('https://raw.githubusercontent.com/nlucian/covid19/master/datasets/lockdown_country_dates.csv')\n",
    "lockdown_Romania=lockdown_dates.loc[lockdown_dates['Country/Region'] == 'Romania']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:45.808591Z",
     "start_time": "2020-05-23T19:31:45.753184Z"
    }
   },
   "outputs": [],
   "source": [
    "# this part is unpivotting the table from the wide format to the long format\n",
    "confirmed_long = numbers_confirmed.melt(id_vars=[\"Province/State\", \"Country/Region\", \"Lat\", \"Long\"], var_name=\"Date\", value_name=\"Confirmed\").fillna('')\n",
    "dead_long = numbers_dead.melt(id_vars=[\"Province/State\", \"Country/Region\", \"Lat\", \"Long\"], var_name=\"Date\", value_name=\"Deaths\").fillna('')\n",
    "recovered_long = numbers_recovered.melt(id_vars=[\"Province/State\", \"Country/Region\", \"Lat\", \"Long\"], var_name=\"Date\", value_name=\"Recovered\").fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:45.920031Z",
     "start_time": "2020-05-23T19:31:45.810869Z"
    }
   },
   "outputs": [],
   "source": [
    "# turn the 3 different tables into a single table with all the information, confirmed, dead and recovered\n",
    "\n",
    "daily_info = dead_long.merge(confirmed_long).merge(recovered_long).drop(['Lat', 'Long'], axis=1)\n",
    "daily_info.tail(5)\n",
    "\n",
    "daily_sum=daily_info.groupby(['Date'],as_index=True).sum()\n",
    "daily_sum.tail(5)\n",
    "\n",
    "#calculate daily values of deaths, confirmed and recovered \n",
    "daily_values=daily_sum.diff(periods=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### world daily values combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:45.931887Z",
     "start_time": "2020-05-23T19:31:45.921947Z"
    }
   },
   "outputs": [],
   "source": [
    "daily_values.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:45.951977Z",
     "start_time": "2020-05-23T19:31:45.934097Z"
    }
   },
   "outputs": [],
   "source": [
    "daily_info['Date'] = pd.to_datetime(daily_info['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:45.956817Z",
     "start_time": "2020-05-23T19:31:45.953636Z"
    }
   },
   "outputs": [],
   "source": [
    "# project constant values\n",
    "# the dataset is updated daily - we need the values of confirmed cases for the last date\n",
    "\n",
    "CONFIRMED_last_date = numbers_confirmed.columns.to_list()[-1]\n",
    "DEATHS_last_date    = numbers_dead.columns.to_list()[-1]\n",
    "RECOVERED_last_date = numbers_recovered.columns.to_list()[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:45.961996Z",
     "start_time": "2020-05-23T19:31:45.959107Z"
    }
   },
   "outputs": [],
   "source": [
    "# data preparation for maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:45.969169Z",
     "start_time": "2020-05-23T19:31:45.963660Z"
    }
   },
   "outputs": [],
   "source": [
    "# we only need the country and the total cases for now\n",
    "df1 = numbers_confirmed.loc[:,'Province/State' : 'Long']\n",
    "df2 = numbers_confirmed.iloc[:,-1]\n",
    "\n",
    "frames = [df1, df2]\n",
    "\n",
    "confirmed_cases_temp = pd.concat(frames, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:45.977960Z",
     "start_time": "2020-05-23T19:31:45.970961Z"
    }
   },
   "outputs": [],
   "source": [
    "confirmed_cases = confirmed_cases_temp.groupby(['Country/Region'], \n",
    "                                               as_index=False)[CONFIRMED_last_date].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:46.000178Z",
     "start_time": "2020-05-23T19:31:45.979836Z"
    }
   },
   "outputs": [],
   "source": [
    "array_of_provinces = {'Denmark': 'Greenland'}\n",
    "\n",
    "# we want to define some provinces as individual countries\n",
    "# since we already do a group by we also have to subtract the number of cases from the group by reuslts\n",
    "def keep_provinces_as_countries(provinces, df_before_grp_by, df_after_grp_by, last_column_date_string):\n",
    "    for country in provinces:\n",
    "        print(\"_Merging into '{}' the values from '{}'.\".format(country, provinces.get(country)))\n",
    "        province_cases = df_before_grp_by[df_before_grp_by['Province/State'] == provinces.get(country)][last_column_date_string]\n",
    "        \n",
    "        province_cases_value = province_cases.to_list()[0]\n",
    "        print(\"_Province_cases {}\".format(province_cases_value))\n",
    "        \n",
    "        to_subtract_from = df_after_grp_by.loc[df_after_grp_by['Country/Region'] == country, [last_column_date_string]][last_column_date_string].to_list()[0]\n",
    "        print(\"_value after group by {}\".format(to_subtract_from))\n",
    "        \n",
    "        final_value = to_subtract_from - province_cases_value\n",
    "        print(\"_Province cases final value {}\".format(final_value))\n",
    "        \n",
    "        df_after_grp_by.loc[df_after_grp_by['Country/Region'] == country ,[last_column_date_string]]  = final_value\n",
    "        \n",
    "        print(\"_Appending country {} with cases {}\".format(provinces.get(country), province_cases_value))\n",
    "        return df_after_grp_by.append({'Country/Region' : provinces.get(country), str(CONFIRMED_last_date) : province_cases_value}, ignore_index=True)\n",
    "    \n",
    "confirmed_cases = keep_provinces_as_countries(array_of_provinces, confirmed_cases_temp, confirmed_cases, CONFIRMED_last_date)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:46.006639Z",
     "start_time": "2020-05-23T19:31:46.002987Z"
    }
   },
   "outputs": [],
   "source": [
    "confirmed_cases = confirmed_cases.rename(columns = {'Country/Region': 'country', CONFIRMED_last_date: 'covid_cases'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:46.014342Z",
     "start_time": "2020-05-23T19:31:46.010445Z"
    }
   },
   "outputs": [],
   "source": [
    "confirmed_cases = confirmed_cases.sort_values(by = ['covid_cases'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:47.819041Z",
     "start_time": "2020-05-23T19:31:46.016333Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load GeoJSON of countries\n",
    "countries_geojson = gmaps.geojson_geometries.load_geometry('countries') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:47.825086Z",
     "start_time": "2020-05-23T19:31:47.821066Z"
    }
   },
   "outputs": [],
   "source": [
    "dict_confirmed_cases = pd.Series(confirmed_cases.covid_cases.values, index=confirmed_cases.country).to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### update keys to match the geojson namings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The left-hand side is the gmaps definition of countries which must be mapped to the github source of covid cases per country.\n",
    "\n",
    "There are 3 cases:\n",
    "\n",
    "There is either no  mapping at all since the github repo does not track the number of cases for the given country;\n",
    "There is a name mismatching  which must be corrected;\n",
    "The region/country in gmaps is part of a country so we cumulate the cases under the mother country;\n",
    "\n",
    "eg.  if the name is wrong -> replacement of the github country name with the gmaps naming;\n",
    "eg.  if some islands like Cayman Islands are owned by UK we display it under UK;\n",
    "eg. no country present in github from the gmap list (since we iterate through all the countries, we just ignore it)\n",
    "\n",
    "<ul>\n",
    "    <li>Aland -> not found</li>\n",
    "    <li>America Samoa ->  not found</li>\n",
    "    <li>Antarctica -> not found</li>\n",
    "    <li>French Southern and Antarctic Lands -> not found</li>\n",
    "    <li>Northern Cyprus -> Cyprus</li>\n",
    "    <li>Cayman Islands -> UK</li>\n",
    "    <li>Curacao -> Netherlands</li>\n",
    "    <li>The Bahamas -> Bahamas</li>\n",
    "    <li>Repubulc of Congo -> Congo (Brazzavilli)</li>\n",
    "    <li>Democratic Repubulc of the Congo -> Congo (Kinshasa)</li>\n",
    "    <li>Comoros -> not found</li>\n",
    "    <li>Cape Verde -> Cabo Verde</li>\n",
    "    <li>CuraÃ§ao -> Netherlands</li>\n",
    "    <li>Cayman Islands -> UK</li>\n",
    "    <li>Falkland Islands -> UK</li>\n",
    "    <li>Faroe Islands -> Denmark</li>\n",
    "    <li>Federated States of Micronesia -> not found</li>\n",
    "    <li>Guinea-Bissau -> Guinea Bissau</li>\n",
    "    <li>Hong Kong S.A.R -> China</li>\n",
    "    <li>Isli of Man -> UK</li>\n",
    "    <li>Baykonur Cosmodrome -> not found</li>\n",
    "    <li>Siachen Glacier -> not found</li>\n",
    "    <li>South Korea -> Korea, South</li>\n",
    "    <li>Lesotho -> not found</li>\n",
    "    <li>North Macedonia -> Macedonia</li>\n",
    "    <li>Myanmar -> Burma</li>\n",
    "    <li>Northern Mariana Islands -> not found</li>\n",
    "    <li>New Calidonia -> France</li>\n",
    "    <li>Niue -> not found</li>\n",
    "    <li>Palau -> not found</li>\n",
    "    <li>North Korea -> Kim Jong is hiding these days </li>\n",
    "    <li>Palistine -> not found</li>\n",
    "    <li>French Polynesia -> France</li>\n",
    "    <li>Solomon Islands -> not found</li>\n",
    "    <li>Saint helina -> not found</li>\n",
    "    <li>South Georgia and South Sandwich Islands -> not found</li>\n",
    "    <li>Somaulland -> not found</li>\n",
    "    <li>Saint Pierre and Miquelon,France -> France</li>\n",
    "    <li>Repubulc of Serbia -> Serbia</li>\n",
    "    <li>Swaziland -> not found</li>\n",
    "    <li>Tajikistan -> not found</li>\n",
    "    <li>East Timor -> Timor-Leste</li>\n",
    "    <li>Turkmenistan -> not found</li>\n",
    "    <li>Taiwan -> Taiwan*</li>\n",
    "    <li>United States Virgin Islands-> UK</li>\n",
    "    <li>Samoa -> not found</li>\n",
    "    <li>Yemen -> not found</li>\n",
    "    \n",
    "<ul/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:47.836050Z",
     "start_time": "2020-05-23T19:31:47.832339Z"
    }
   },
   "outputs": [],
   "source": [
    "def replace_country_key(old_key, new_key, dictionary):\n",
    "    try:\n",
    "        dictionary[new_key] = dictionary[old_key]\n",
    "        del dict_confirmed_cases[old_key]\n",
    "    except Exception as e:\n",
    "        print(\"Error while mapping country {} or country already mapped.\".format(str(e)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:47.849676Z",
     "start_time": "2020-05-23T19:31:47.842754Z"
    }
   },
   "outputs": [],
   "source": [
    "# name mapping error\n",
    "replace_country_key('US', 'United States of America', dict_confirmed_cases)\n",
    "replace_country_key('Bahamas', 'The Bahamas', dict_confirmed_cases)\n",
    "replace_country_key('Czechia', 'Czech Republic', dict_confirmed_cases)\n",
    "\n",
    "replace_country_key('Congo (Brazzaville)', 'Republic of Congo', dict_confirmed_cases)\n",
    "replace_country_key('Congo (Kinshasa)', 'Democratic Republic of the Congo', dict_confirmed_cases)\n",
    "\n",
    "replace_country_key('Cabo Verde', 'Cape Verde', dict_confirmed_cases)\n",
    "replace_country_key('Guinea-Bissau', 'Guinea Bissau', dict_confirmed_cases)\n",
    "replace_country_key('Korea, South', 'South Korea', dict_confirmed_cases)\n",
    "replace_country_key('North Macedonia', 'Macedonia', dict_confirmed_cases)\n",
    "replace_country_key('Burma','Myanmar', dict_confirmed_cases)\n",
    "replace_country_key('Serbia', 'Republic of Serbia', dict_confirmed_cases)\n",
    "replace_country_key('Timor-Leste', 'East Timor', dict_confirmed_cases)\n",
    "replace_country_key('Taiwan*', 'Taiwan', dict_confirmed_cases)\n",
    "replace_country_key('Tanzania', 'United Republic of Tanzania', dict_confirmed_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:47.854363Z",
     "start_time": "2020-05-23T19:31:47.851517Z"
    }
   },
   "outputs": [],
   "source": [
    "# custom data for some of the next map trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:47.862010Z",
     "start_time": "2020-05-23T19:31:47.857554Z"
    }
   },
   "outputs": [],
   "source": [
    "dict_confirmed_cases\n",
    "dict_confirmed_cases_df = pd.DataFrame(list(dict_confirmed_cases.items()), \n",
    "                                       columns = ['countries','covid_cases']) \n",
    "\n",
    "dict_confirmed_cases_df['countries'] = dict_confirmed_cases_df['countries'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAPS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Worldmap with total COVID-19 cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### select the color you wish to generate the map with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:47.866972Z",
     "start_time": "2020-05-23T19:31:47.864310Z"
    }
   },
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:47.874284Z",
     "start_time": "2020-05-23T19:31:47.869294Z"
    }
   },
   "outputs": [],
   "source": [
    "dict_confirmed_cases_df['covid_cases'] =  dict_confirmed_cases_df['covid_cases'].astype(int)\n",
    "dict_confirmed_cases_df['covid_cases'] =  dict_confirmed_cases_df['covid_cases'].apply(apply_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:47.881105Z",
     "start_time": "2020-05-23T19:31:47.876541Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_covid_map(fill_color):\n",
    "\n",
    "    legend_name = 'COVID-19 cases worldwide'\n",
    "    m3 = folium.Map(location=[51.505, -0.09], tiles='cartodbpositron', max_bounds=True,\n",
    "                   zoom_start=1.5, min_zoom = 2)\n",
    "\n",
    "    folium.Choropleth(\n",
    "        \n",
    "        geo_data=countries_geojson,\n",
    "        data=dict_confirmed_cases_df,\n",
    "        fill_color=fill_color,\n",
    "        legend_named='COVID-19 cases worldwide (log scale)',\n",
    "        columns=['countries', 'covid_cases'],\n",
    "        key_on='feature.properties.name',\n",
    "        fill_opacity=0.9,\n",
    "        line_opacity=0.1,\n",
    "        nan_fill_color='ffffff'\n",
    "    ).add_to(m3)\n",
    "    \n",
    "    display(m3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:47.889979Z",
     "start_time": "2020-05-23T19:31:47.882697Z"
    }
   },
   "outputs": [],
   "source": [
    "map_output_widget = widgets.Output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:47.905245Z",
     "start_time": "2020-05-23T19:31:47.892100Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "map_colors =  {'Green':'BuGn', 'Red':'RdPu'}\n",
    "\n",
    "select_variable = widgets.Dropdown(\n",
    "    options=map_colors,\n",
    "    value=map_colors.get('Blue'),\n",
    "    description='Colors'\n",
    ")\n",
    "\n",
    "def get_and_plot(b):\n",
    "    with map_output_widget:\n",
    "        clear_output()\n",
    "        print(select_variable.value)\n",
    "        generate_covid_map(select_variable.value)\n",
    "        \n",
    "select_variable.observe(get_and_plot, names='value')\n",
    "\n",
    "display(select_variable)\n",
    "display(map_output_widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Worldmap with COVID-19 mortality \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:47.911280Z",
     "start_time": "2020-05-23T19:31:47.906936Z"
    }
   },
   "outputs": [],
   "source": [
    "modified_deaths = numbers_dead[numbers_dead[DEATHS_last_date] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Density Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:48.385290Z",
     "start_time": "2020-05-23T19:31:47.913179Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.style.use(\"cyberpunk\")\n",
    "plt.subplots(figsize=(24, 10))\n",
    "plt.suptitle('Density', fontsize = 25)\n",
    "plt.subplot(1,2,1)\n",
    "(modified_deaths[DEATHS_last_date]).plot.kde()\n",
    "plt.subplot(1,2,2)\n",
    "(np.log10(modified_deaths[DEATHS_last_date])).plot.kde()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If we use the original values, then we won't be able to distinguish the colors of the map (that's why we are going apply $log_{10}$ since the values are more spread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:48.391082Z",
     "start_time": "2020-05-23T19:31:48.387285Z"
    }
   },
   "outputs": [],
   "source": [
    "modified_deaths['Transformed_value'] = np.log10(modified_deaths[DEATHS_last_date])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:48.404471Z",
     "start_time": "2020-05-23T19:31:48.393455Z"
    }
   },
   "outputs": [],
   "source": [
    "df_new = pd.DataFrame(columns = ['Country', 'Date', 'Confirmed', 'Recovered', 'Dead', 'Transformed_value'])    \n",
    "\n",
    "df_new['Country'] = modified_deaths['Country/Region']\n",
    "df_new['Date'] = CONFIRMED_last_date\n",
    "df_new['Confirmed'] = numbers_confirmed[CONFIRMED_last_date]\n",
    "df_new['Dead'] = numbers_dead[DEATHS_last_date]\n",
    "df_new['Recovered'] = numbers_recovered[RECOVERED_last_date]\n",
    "df_new['Transformed_value'] = modified_deaths['Transformed_value']\n",
    "df_new = df_new[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:48.730316Z",
     "start_time": "2020-05-23T19:31:48.414855Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = px.choropleth(\n",
    "    df_new,\n",
    "    locations = 'Country',\n",
    "    locationmode = 'country names',\n",
    "    color = 'Transformed_value',\n",
    "    hover_name = 'Country',\n",
    "    hover_data = ['Confirmed','Recovered','Dead'], \n",
    "    animation_frame= 'Date',\n",
    "    color_continuous_scale=px.colors.diverging.RdYlGn[::-1]\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text =   \" COVID-19 Deaths \" + DEATHS_last_date,\n",
    "    title_x = 0.5,\n",
    "    geo= dict(\n",
    "        showframe= False,\n",
    "        showcoastlines= False,\n",
    "        projection_type = 'equirectangular'\n",
    "    )\n",
    ")\n",
    "\n",
    "display(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### healed vs deaths percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:48.829719Z",
     "start_time": "2020-05-23T19:31:48.732215Z"
    }
   },
   "outputs": [],
   "source": [
    "# turn the 3 different tables into a single table with all the information, confirmed, dead and recovered\n",
    "daily_info = dead_long.merge(confirmed_long).merge(recovered_long).drop(['Lat', 'Long'], axis=1)\n",
    "daily_sum  = daily_info.groupby(['Date'],as_index=True).sum()\n",
    "\n",
    "#calculate daily values of deaths, confirmed and recovered \n",
    "daily_values = daily_sum.diff(periods=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:48.837042Z",
     "start_time": "2020-05-23T19:31:48.831719Z"
    }
   },
   "outputs": [],
   "source": [
    "daily_sum['death_percentage'] = daily_sum['Deaths']/daily_sum['Confirmed'] *100\n",
    "daily_sum['heal_percentage']  = daily_sum['Recovered']/daily_sum['Confirmed'] *100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:48.843475Z",
     "start_time": "2020-05-23T19:31:48.839211Z"
    }
   },
   "outputs": [],
   "source": [
    "daily_sum.reset_index(level=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:49.877416Z",
     "start_time": "2020-05-23T19:31:48.845396Z"
    }
   },
   "outputs": [],
   "source": [
    "def plotHealDeathPercentage():   \n",
    "        plt.style.use(\"cyberpunk\")\n",
    "        fig = plt.figure(figsize=(20,10))\n",
    "        \n",
    "        plt.locator_params(axis='x', nbins=15)\n",
    "        \n",
    "        plt.plot(daily_sum['Date'], daily_sum['death_percentage'], label = 'Death Percentage')\n",
    "        plt.plot(daily_sum['Date'], daily_sum['heal_percentage'], label = 'Heal Percentage')\n",
    "        \n",
    "        plt.legend(loc=2, prop={'size': 18})\n",
    "        plt.xticks(rotation=90, ha='right', fontsize=\"x-large\")\n",
    "        plt.yticks(fontsize=\"x-large\")\n",
    "        \n",
    "        ax = plt.gca()\n",
    "        temp = ax.xaxis.get_ticklabels()\n",
    "        temp = list(set(temp) - set(temp[::3]))\n",
    "        for label in temp:\n",
    "            label.set_visible(False)\n",
    "        \n",
    "        \n",
    "        mplcyberpunk.make_lines_glow(ax)\n",
    "\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "plotHealDeathPercentage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Countries Investigated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:49.883492Z",
     "start_time": "2020-05-23T19:31:49.879043Z"
    }
   },
   "outputs": [],
   "source": [
    "# data modeling for the investigated countries plot\n",
    "\n",
    "def dataFrameForCountry(country):\n",
    "    country_data=daily_info.loc[daily_info['Country/Region'] == country]\n",
    "    country_data=country_data.drop([\"Province/State\",\"Country/Region\"], axis=1)\n",
    "    country_data.set_index('Date', inplace = True) \n",
    "\n",
    "    country_data_daily = country_data.diff(periods=1)\n",
    "    country_data_daily = country_data_daily[(country_data_daily > 0).any(axis=1)]\n",
    "\n",
    "    country_data_daily['DateOf'] = country_data_daily.index\n",
    "    return country_data_daily\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:49.905048Z",
     "start_time": "2020-05-23T19:31:49.885526Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "countries_Investigated = ['Romania', 'Italy', 'Sweden', 'Belarus','Iran','Belgium', 'Poland','Germany', 'Brazil','Mexico','Russia','Turkey','Indonesia','Egypt','Portugal','Ukraine','Pakistan','Hungary']\n",
    "select_countries = widgets.Dropdown(\n",
    "    options=countries_Investigated,\n",
    "    value=countries_Investigated[0],\n",
    "    description='Countries'\n",
    ")\n",
    "\n",
    "ci_output = widgets.Output()\n",
    "display(widgets.VBox([ci_output, select_countries]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:49.918943Z",
     "start_time": "2020-05-23T19:31:49.907015Z"
    }
   },
   "outputs": [],
   "source": [
    "@ci_output.capture()\n",
    "def RestrictionsEffectForCountry(country):\n",
    "    plt.style.use(\"cyberpunk\")\n",
    "    \n",
    "    dataFrame = dataFrameForCountry(country)\n",
    "    \n",
    "    dataFrame.plot(y=['Confirmed','Deaths','Recovered'],kind='bar',figsize=(20,10),color=['orange','darkred','lightgreen'])\n",
    "\n",
    "\n",
    "    lockdown_date_type=lockdown_dates.loc[lockdown_dates['Country/Region'] == country]\n",
    "  \n",
    "    if(not(StringisNaN(lockdown_date_type.iloc[0]['Date']))):\n",
    "        date_format = \"%Y-%m-%d\"\n",
    "        \n",
    "        first_lockdown_measure=str(datetime.strptime(lockdown_date_type.iloc[0]['Date'],date_format).date())\n",
    "        dataFrame['DateOf'] = pd.to_datetime(dataFrame['DateOf'])\n",
    "        plotdataFrame=dataFrame.reset_index()\n",
    "        plotdataFrame[\"DateOf\"] = plotdataFrame[\"DateOf\"].apply(lambda x: datetime.combine(x.date(), datetime.min.time()))\n",
    "        plotdataFrame[\"DateOf\"] = plotdataFrame[\"DateOf\"].dt.strftime(\"%Y-%m-%d\")\n",
    "        \n",
    "        delta=plotdataFrame.loc[plotdataFrame[\"DateOf\"] == first_lockdown_measure].index[0]\n",
    "        \n",
    "        plt.axvspan(0, delta, facecolor='#FFFF33', alpha=0.5,zorder=0.1)\n",
    "        plt.axvspan(delta, len(dataFrame.index), facecolor='green', alpha=0.5,zorder=0.1)\n",
    "        plt.suptitle(country+' (quarantine started on '+ first_lockdown_measure,fontsize=15)\n",
    "    else:\n",
    "        plt.suptitle(country+' (no quarantine)', fontsize=15)\n",
    "    plt.legend(loc=1, prop={'size': 15})\n",
    "    ax = plt.gca()\n",
    "    temp = ax.xaxis.get_ticklabels()\n",
    "    temp = list(set(temp) - set(temp[::3]))\n",
    "    for label in temp:\n",
    "        label.set_visible(False)\n",
    "    x_axis = ax.axes.get_xaxis()\n",
    "    x_axis.set_label_text('')\n",
    "    ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "    ax.tick_params(axis='both', which='minor', labelsize=15)\n",
    "    mplcyberpunk.make_lines_glow(ax)    \n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:49.923906Z",
     "start_time": "2020-05-23T19:31:49.920843Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_investigated_countries(a):\n",
    "    with ci_output:\n",
    "        clear_output()\n",
    "        print(select_countries.value)\n",
    "        RestrictionsEffectForCountry(select_countries.value)\n",
    "\n",
    "select_countries.observe(plot_investigated_countries, names='value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:49.928861Z",
     "start_time": "2020-05-23T19:31:49.925852Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"last update on the dataset: {}\".format(CONFIRMED_last_date)) # CONFIRMED_last_date = numbers_confirmed.columns.to_list()[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:49.935239Z",
     "start_time": "2020-05-23T19:31:49.930847Z"
    }
   },
   "outputs": [],
   "source": [
    "total_confirmed_case = numbers_confirmed[CONFIRMED_last_date].sum()\n",
    "print(f\"{total_confirmed_case:,} confirmed cases\")\n",
    "\n",
    "total_recovered_cases = numbers_recovered[RECOVERED_last_date].sum()\n",
    "print(f\"{total_recovered_cases:,} recovered\")\n",
    "\n",
    "total_deaths = numbers_dead[RECOVERED_last_date].sum()\n",
    "print(f\"{total_deaths:,} deaths\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:49.941816Z",
     "start_time": "2020-05-23T19:31:49.937207Z"
    }
   },
   "outputs": [],
   "source": [
    "top_ten = numbers_confirmed.sort_values(by = CONFIRMED_last_date  , ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 10 countries - confirmed cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:49.948395Z",
     "start_time": "2020-05-23T19:31:49.944166Z"
    }
   },
   "outputs": [],
   "source": [
    "top_ten['Country/Region']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 10 countries with COVID-19 confirmed cases - last date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:50.366300Z",
     "start_time": "2020-05-23T19:31:49.950314Z"
    }
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(12,8))\n",
    "\n",
    "#plt.figure(figsize=(12,8))\n",
    "ax = sns.barplot(x = CONFIRMED_last_date, y = 'Country/Region', \n",
    "              data = top_ten)\n",
    "ax.set(xlabel='Confirmed Cases', ylabel='Country')\n",
    "\n",
    "for i, (value, name) in enumerate(zip(top_ten[CONFIRMED_last_date], top_ten['Country/Region'])):\n",
    "    ax.text(value, i-0.20,     value,           ha='right')\n",
    "    \n",
    "ax.text(1, 0.4, CONFIRMED_last_date, transform=ax.transAxes, size=46, ha='right')\n",
    "\n",
    "plt.title(\"Top ten countries with confirmed covid cases\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:50.414685Z",
     "start_time": "2020-05-23T19:31:50.369869Z"
    }
   },
   "outputs": [],
   "source": [
    "nrc_grouped_by_country = numbers_confirmed.groupby(['Country/Region'], as_index=False).sum()\n",
    "nrd_grouped_by_country = numbers_dead.groupby(['Country/Region'], as_index=False).sum()\n",
    "nr_grouped_By_country = numbers_recovered.groupby(['Country/Region'], as_index=False).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Animated barcharts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:50.447291Z",
     "start_time": "2020-05-23T19:31:50.419708Z"
    }
   },
   "outputs": [],
   "source": [
    "global category\n",
    "\n",
    "category = 'Confirmed'\n",
    "\n",
    "def draw_barchart(date):\n",
    "    \n",
    "    \n",
    "    if category == 'Confirmed':\n",
    "        df_top10 = (nrc_grouped_by_country.sort_values(by=date,ascending=False).head(10))\n",
    "    elif category == 'Dead':\n",
    "        df_top10 = (nrd_grouped_by_country.sort_values(by=date,ascending=False).head(10))\n",
    "    elif category == 'Recovered':\n",
    "        df_top10 = (nr_grouped_By_country.sort_values(by=date,ascending=False).head(10))\n",
    "    else:\n",
    "        return\n",
    "\n",
    "    df_new = pd.DataFrame(columns = ['Country', 'Date', category])    \n",
    "    \n",
    "    df_new['Country'] = df_top10['Country/Region']\n",
    "    df_new['Date'] = date\n",
    "    df_new[category] = df_top10[date]\n",
    "    df_new = df_new[::-1]\n",
    "    \n",
    "    ax.clear()\n",
    "    \n",
    "    ax.barh(df_new['Country'], df_new[category], color=[\"#980505\",\"#CD1212\",\"#D84E4E\",\"#CB6262\",\"#D39B5F\",\"#F7EC10\",\"#D0F710\",\"#9CF710\",\"#B4D67F\",\"#969C8E\"])\n",
    "    \n",
    "    dx = df_new[category].max() / 200\n",
    "    \n",
    "    for i, (value, name) in enumerate(zip(df_new[category], df_new['Country'])):\n",
    "        ax.text(value-dx, i,     name,           size=14, weight=600, ha='right', va='bottom')\n",
    "        ax.text(value+dx, i-.15, value, size=13, color='k', ha='left', va='center')\n",
    "        \n",
    "    ax.text(1, 0.4, date, transform=ax.transAxes, color='#777777', size=30, ha='right', weight=800)\n",
    "    ax.text(0, 1.06, 'Number of Cases', transform=ax.transAxes, size=12, color='#777777')\n",
    "    ax.xaxis.set_major_formatter(ticker.StrMethodFormatter('{x:,.0f}'))\n",
    "    ax.xaxis.set_ticks_position('top')\n",
    "    ax.tick_params(axis='x', colors='#777777', labelsize=12)\n",
    "    ax.set_yticks([])\n",
    "    ax.margins(0, 0.01)\n",
    "    ax.grid(which='major', axis='x', linestyle='-')\n",
    "    ax.set_axisbelow(True)\n",
    "    ax.text(0, 1.1, 'The number of ' + category + ' cases up to ' + CONFIRMED_last_date,\n",
    "            transform=ax.transAxes, size=24, weight=600, ha='left')\n",
    "    ax.text(1, 0, 'credit @jburnmurdoch', transform=ax.transAxes, ha='right',\n",
    "            color='#777777', bbox=dict(facecolor='white', alpha=0.8, edgecolor='white'))\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:50.456298Z",
     "start_time": "2020-05-23T19:31:50.451530Z"
    }
   },
   "outputs": [],
   "source": [
    "# animator = F.FuncAnimation(fig,draw_barchart,frames = numbers_confirmed.columns[3:], interval = 150, repeat = True)\n",
    "# HTML(animator.to_jshtml())\n",
    "# animator.save(r'confirmed_23_may.gif', writer='imagemagick', fps=60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:50.659432Z",
     "start_time": "2020-05-23T19:31:50.463474Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('dead_23_may.gif','rb') as f: \n",
    "    display(Image(data=f.read(), format='png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:50.917850Z",
     "start_time": "2020-05-23T19:31:50.672722Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('recovered_23_may.gif','rb') as f: \n",
    "    display(Image(data=f.read(), format='png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:51.233989Z",
     "start_time": "2020-05-23T19:31:50.936126Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('confirmed_23_may.gif','rb') as f: \n",
    "    display(Image(data=f.read(), format='png'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:51.264822Z",
     "start_time": "2020-05-23T19:31:51.237291Z"
    }
   },
   "outputs": [],
   "source": [
    "X_confirmed = pd.DataFrame(numbers_confirmed.iloc[:,4:].sum()).rename(columns = {0:'t0'})\n",
    "print(X_confirmed.shape)\n",
    "X_dead = pd.DataFrame(numbers_dead.iloc[:,4:].sum()).rename(columns = {0:'t0'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:51.273365Z",
     "start_time": "2020-05-23T19:31:51.267190Z"
    }
   },
   "outputs": [],
   "source": [
    "def shift_dataset(n, df):\n",
    "    scoped_df = copy.deepcopy(df)\n",
    "    \n",
    "    if n <= 0:\n",
    "        print('n must be > 0!')\n",
    "        return\n",
    "    \n",
    "    for i in range(n):\n",
    "        scoped_df['t' + str(i+1)] = (scoped_df['t' + str(i)].shift(-1))\n",
    "        scoped_df.dropna(inplace=True)\n",
    "    \n",
    "    x = np.array(scoped_df.iloc[:,:n])\n",
    "    y = np.array(scoped_df.iloc[:, n])\n",
    "    print(scoped_df.shape)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:51.302222Z",
     "start_time": "2020-05-23T19:31:51.278064Z"
    }
   },
   "outputs": [],
   "source": [
    "x_confirmed, y_confirmed = shift_dataset(4, X_confirmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:51.312446Z",
     "start_time": "2020-05-23T19:31:51.304457Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"x_confirmed shape: {}\\ny_confirmed shape: {}\".format(x_confirmed.shape, y_confirmed.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:51.338552Z",
     "start_time": "2020-05-23T19:31:51.315742Z"
    }
   },
   "outputs": [],
   "source": [
    "x_dead, y_dead = shift_dataset(4, X_dead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:51.347373Z",
     "start_time": "2020-05-23T19:31:51.342077Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"x_dead shape: {}\\ny_dead shape: {}\".format(x_dead.shape, y_dead.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:52.044564Z",
     "start_time": "2020-05-23T19:31:51.349672Z"
    }
   },
   "outputs": [],
   "source": [
    "regressor = LinearRegression()\n",
    "\n",
    "for shift in np.arange(1, 7):\n",
    "    X_confirmed_copy=copy.deepcopy(X_confirmed)\n",
    "    \n",
    "    x_confirmed_shift, y_confirmed_shift=shift_dataset(shift, X_confirmed_copy)\n",
    "    \n",
    "    print(x_confirmed_shift.shape)\n",
    "    x_confirmed_log=np.log(x_confirmed_shift)\n",
    "    y_confirmed_log=np.log(y_confirmed_shift)\n",
    "    \n",
    "    x_confirmed_log_train =  x_confirmed_log[:80-shift]\n",
    "    y_confirmed_log_train =  y_confirmed_log[:80-shift]\n",
    "    \n",
    "    x_confirmed_log_test  = x_confirmed_log[80-shift:]\n",
    "    y_confirmed_log_test  = y_confirmed_log[80-shift:]\n",
    "\n",
    "    regressor.fit(x_confirmed_log_train, y_confirmed_log_train)\n",
    "    \n",
    "    y_pred=regressor.predict(x_confirmed_log_test)\n",
    "    regressor.fit(x_confirmed_log_train,y_confirmed_log_train)\n",
    "    y_pred=regressor.predict(x_confirmed_log_test)\n",
    "    y_pred_exp=np.exp(y_pred)\n",
    "    \n",
    "  \n",
    "    print(\"Prediction of confirmed cases with a shift of \" + str(shift)+ \" gives R2 Score of \"+str(r2_score(y_pred_exp,y_confirmed_shift[80-shift:])))\n",
    "    if shift==5:\n",
    "        plt.plot(np.concatenate((np.exp(regressor.predict(x_confirmed_log_train)),y_pred_exp),axis=0),label='Prediction')\n",
    "        plt.plot(y_confirmed_shift, label='True Values')\n",
    "        plt.title(\"True vs Predicted Confirmed Cases\")\n",
    "        plt.legend(loc=1, prop={'size': 15})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:52.741047Z",
     "start_time": "2020-05-23T19:31:52.048093Z"
    }
   },
   "outputs": [],
   "source": [
    "regressor = LinearRegression()\n",
    "\n",
    "for shift in np.arange(1, 7):\n",
    "    X_dead_copy=copy.deepcopy(X_dead)\n",
    "    x_dead_shift, y_dead_shift=shift_dataset(shift, X_dead_copy)\n",
    "    \n",
    "    x_dead_log=np.log(x_dead_shift)\n",
    "    y_dead_log=np.log(y_dead_shift)\n",
    "    x_dead_log_train=x_dead_log[:80-shift]\n",
    "    x_dead_log_test=x_dead_log[80-shift:]\n",
    "    y_dead_log_train=y_dead_log[:80-shift]\n",
    "    y_dead_log_test=y_dead_log[80-shift:]\n",
    "    regressor.fit(x_dead_log_train,y_dead_log_train)\n",
    "    y_pred=regressor.predict(x_dead_log_test)\n",
    "    regressor.fit(x_dead_log_train,y_dead_log_train)\n",
    "    y_pred=regressor.predict(x_dead_log_test)\n",
    "    y_pred_exp=np.exp(y_pred)\n",
    "    \n",
    "  \n",
    "    print(\"Prediction of dead cases with a shift of \" + str(shift)+ \" gives R2 Score of \"+str(r2_score(y_pred_exp,y_dead_shift[80-shift:])))\n",
    "    if shift==5:\n",
    "        plt.plot(np.concatenate((np.exp(regressor.predict(x_dead_log_train)),y_pred_exp),axis=0),label='Prediction')\n",
    "        plt.plot(y_dead_shift, label='True Values')\n",
    "        plt.title(\"True vs Predicted dead Cases\")\n",
    "        plt.legend(loc=1, prop={'size': 15})\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-10T13:23:27.483362Z",
     "start_time": "2020-05-10T13:23:27.481076Z"
    }
   },
   "source": [
    "# SVM -> SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:52.760120Z",
     "start_time": "2020-05-23T19:31:52.755185Z"
    }
   },
   "outputs": [],
   "source": [
    "def processDataForSVR(log_, x, y):\n",
    "\n",
    "    if log_:\n",
    "        svr_x_generic_log = np.log(x)\n",
    "        svr_y_generic_log = np.log(y)\n",
    "    else:\n",
    "        svr_x_generic_log = x\n",
    "        svr_y_generic_log = y\n",
    "        \n",
    "    svr_x_generic_training_log, svr_x_generic_test_log, svr_y_generic_training_log, svr_y_generic_test_log = train_test_split(svr_x_generic_log, svr_y_generic_log, test_size = 0.2, shuffle=False)\n",
    "    \n",
    "    return svr_x_generic_training_log, svr_y_generic_training_log, svr_x_generic_test_log, svr_y_generic_test_log\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:52.793040Z",
     "start_time": "2020-05-23T19:31:52.786387Z"
    }
   },
   "outputs": [],
   "source": [
    "def perform_grid_earch(model, x, y):\n",
    "    grid_search = GridSearchCV(estimator=svr2,\n",
    "            param_grid={\n",
    "                'C': [0.1, 1],\n",
    "                'epsilon': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1],\n",
    "                'degree': [2, 3],            \n",
    "                'coef0': [0.1, 0.01, 0.001]},\n",
    "            cv=5, scoring='neg_mean_squared_error', verbose=0)\n",
    "    results = grid_search.fit(x, y)\n",
    "    \n",
    "    print(\"Best results {}\".format(results.best_params_))\n",
    "    \n",
    "#perform_grid_earch(svr2, svr_c_x_tr, svr_c_y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:53.783690Z",
     "start_time": "2020-05-23T19:31:52.796987Z"
    }
   },
   "outputs": [],
   "source": [
    "# tr stands for trainig and te for test\n",
    "# c stands for confirmed and d for dead\n",
    "svr_c_x_tr, svr_c_y_tr, svr_c_x_te, svr_c_y_te = processDataForSVR(True, x_confirmed, y_confirmed)\n",
    "\n",
    "# the most important parameter for SVR is the type of the kernel:\n",
    "# - linaer\n",
    "# - polynomial\n",
    "# - gaussian\n",
    "\n",
    "svr2 = SVR(kernel='poly', C=1, coef0= 0.01, degree=3, epsilon=0.05)\n",
    "svr2.fit(svr_c_x_tr, svr_c_y_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### svr - confirmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:53.791693Z",
     "start_time": "2020-05-23T19:31:53.785726Z"
    }
   },
   "outputs": [],
   "source": [
    "svr_c_y_pred = svr2.predict(svr_c_x_te)\n",
    "\n",
    "print(svr_c_y_pred.shape)\n",
    "print(svr_c_y_te.shape)\n",
    "\n",
    "r2_score(svr_c_y_te, svr_c_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:54.091079Z",
     "start_time": "2020-05-23T19:31:53.794376Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(np.concatenate((np.exp(svr2.predict(svr_c_x_tr)), np.exp(svr_c_y_pred)),axis=0),label='Prediction')\n",
    "plt.plot(y_confirmed, label='True Values')\n",
    "plt.title(\"True vs Predicted dead Cases\")\n",
    "plt.legend(loc=1, prop={'size': 15})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:54.098129Z",
     "start_time": "2020-05-23T19:31:54.093848Z"
    }
   },
   "outputs": [],
   "source": [
    "# tr stands for trainig and te for test\n",
    "# c stands for confirmed and d for dead\n",
    "svr_d_x_tr, svr_d_y_tr, svr_d_x_te, svr_d_y_te = processDataForSVR(True, x_dead, y_dead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:54.247361Z",
     "start_time": "2020-05-23T19:31:54.100083Z"
    }
   },
   "outputs": [],
   "source": [
    "svr2 = SVR(kernel='poly', C=1, coef0= 0.01, degree=3, epsilon=0.05)\n",
    "svr2.fit(svr_d_x_tr, svr_d_y_tr)\n",
    "\n",
    "svr_d_y_pred = svr2.predict(svr_d_x_te)\n",
    "\n",
    "print(svr_c_y_pred.shape)\n",
    "print(svr_c_y_te.shape)\n",
    "\n",
    "r2_score(svr_d_y_te, svr_d_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:54.488077Z",
     "start_time": "2020-05-23T19:31:54.249244Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [10,10]\n",
    "plt.plot(np.concatenate((np.exp(svr2.predict(svr_d_x_tr)), np.exp(svr_d_y_pred)),axis=0),label='Prediction')\n",
    "plt.plot(y_dead, label='True Values')\n",
    "plt.title(\"True vs Predicted dead Cases\")\n",
    "plt.legend(loc=1, prop={'size': 15})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:54.500109Z",
     "start_time": "2020-05-23T19:31:54.490615Z"
    }
   },
   "outputs": [],
   "source": [
    "n = 1\n",
    "\n",
    "x_confirmed, y_confirmed = shift_dataset(n, X_confirmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:54.507428Z",
     "start_time": "2020-05-23T19:31:54.502695Z"
    }
   },
   "outputs": [],
   "source": [
    "x_confirmed_train, x_confirmed_test, y_confirmed_train, y_confirmed_test = train_test_split(x_confirmed,\n",
    "                                                                                            y_confirmed, test_size = 0.2)\n",
    "x_confirmed_train = x_confirmed_train.reshape(x_confirmed_train.shape[0],n)\n",
    "x_confirmed_test = x_confirmed_test.reshape(x_confirmed_test.shape[0],n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:54.519835Z",
     "start_time": "2020-05-23T19:31:54.510399Z"
    }
   },
   "outputs": [],
   "source": [
    "x_dead, y_dead = shift_dataset(n, X_dead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:54.534221Z",
     "start_time": "2020-05-23T19:31:54.523018Z"
    }
   },
   "outputs": [],
   "source": [
    "covid_worldwide = pd.DataFrame({'Confirmed' : [], 'Dead' : [], 'Recovered' : []})\n",
    "covid_worldwide['Confirmed'] = numbers_confirmed.iloc[:,4:].sum()\n",
    "covid_worldwide['Dead'] = numbers_dead.iloc[:,4:].sum()\n",
    "covid_worldwide['Recovered'] = numbers_recovered.iloc[:,4:].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:54.541302Z",
     "start_time": "2020-05-23T19:31:54.536354Z"
    }
   },
   "outputs": [],
   "source": [
    "def forecast(x, model, n, scaler):\n",
    "    \n",
    "    \n",
    "    # n = number of days ahead to forecast\n",
    "    # x =last confirmed/dead/recovered value\n",
    "    # model = lasso/lstm etc.\n",
    "    \n",
    "    y_pred = []\n",
    "    curr_value = scaler.transform(x)\n",
    "    \n",
    "    for i in range(n):\n",
    "        val = model.predict(curr_value).reshape(-1,1)\n",
    "        y_pred.append(val[0,0])\n",
    "        curr_value = scaler.transform(val)\n",
    "        \n",
    "    \n",
    "    return y_pred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:54.551579Z",
     "start_time": "2020-05-23T19:31:54.544885Z"
    }
   },
   "outputs": [],
   "source": [
    "def forecast_poly(x, model, n, poly_features, scaler):\n",
    "    \n",
    "    \n",
    "    # n = number of days ahead to forecast\n",
    "    # x =last confirmed/dead/recovered value\n",
    "    # model = lasso/lstm etc.\n",
    "    \n",
    "    y_pred = []\n",
    "    scaled = scaler.transform(x)\n",
    "    curr_value = poly_features.fit_transform(scaled).reshape(1,-1)\n",
    "    \n",
    "    for i in range(n):\n",
    "        val = model.predict(curr_value)[0]\n",
    "        y_pred.append(val)\n",
    "        \n",
    "        \n",
    "        \n",
    "        curr_value = poly_features.fit_transform(scaler.transform(val.reshape(1,1))).reshape(1,-1)\n",
    "        \n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:54.561150Z",
     "start_time": "2020-05-23T19:31:54.554622Z"
    }
   },
   "outputs": [],
   "source": [
    "def forecast_lstm(x, model, n, scaler):\n",
    "    \n",
    "    \n",
    "    # n = number of days ahead to forecast\n",
    "    # x =last confirmed/dead/recovered value\n",
    "    # model = lasso/lstm etc.\n",
    "    \n",
    "    y_pred = []\n",
    "    curr_value = scaler.transform(x).reshape(1,1,-1)\n",
    "    \n",
    "    for i in range(n):\n",
    "        val = model.predict(curr_value)\n",
    "        y_pred.append(val[0,0])\n",
    "        curr_value = scaler.transform(val).reshape(1,1,-1)\n",
    "        \n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forecast variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:54.567603Z",
     "start_time": "2020-05-23T19:31:54.564321Z"
    }
   },
   "outputs": [],
   "source": [
    "last_conf_value = covid_worldwide['Confirmed'].iloc[-1].reshape(1,1)\n",
    "days = np.arange(covid_worldwide.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:54.576412Z",
     "start_time": "2020-05-23T19:31:54.569773Z"
    }
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "x_confirmed_train = scaler.fit_transform(x_confirmed_train)\n",
    "x_confirmed_test = scaler.transform(x_confirmed_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:54.581802Z",
     "start_time": "2020-05-23T19:31:54.578911Z"
    }
   },
   "outputs": [],
   "source": [
    "poly_features = PolynomialFeatures(degree = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:54.587198Z",
     "start_time": "2020-05-23T19:31:54.583619Z"
    }
   },
   "outputs": [],
   "source": [
    "x_confirmed_poly = poly_features.fit_transform(x_confirmed_train)\n",
    "x_conf_test_poly = poly_features.fit_transform(x_confirmed_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:54.598656Z",
     "start_time": "2020-05-23T19:31:54.590485Z"
    }
   },
   "outputs": [],
   "source": [
    "reg = LinearRegression().fit(x_confirmed_poly, y_confirmed_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:54.612467Z",
     "start_time": "2020-05-23T19:31:54.601315Z"
    }
   },
   "outputs": [],
   "source": [
    "r2_training = reg.score(x_confirmed_poly, y_confirmed_train)\n",
    "mse_training = mean_squared_error(y_confirmed_train, reg.predict(x_confirmed_poly))\n",
    "r2_test = reg.score(x_conf_test_poly, y_confirmed_test)\n",
    "mse_testing = mean_squared_error(y_confirmed_test, reg.predict(x_conf_test_poly))\n",
    "print(r2_training,mse_training, r2_test, mse_testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "  <tr>\n",
    "    <th></th>\n",
    "    <th scope=\"col\">MSE</th>\n",
    "    <th scope=\"col\">$R^2$</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th scope=\"row\">Training</th>\n",
    "    <td>39136302.61040542</td>\n",
    "    <td>0.999986</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th scope=\"row\">Testing</th>\n",
    "    <td>47674661.12815987</td>\n",
    "    <td>0.999989 </td>\n",
    "  </tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forecast - polynomial regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:54.624231Z",
     "start_time": "2020-05-23T19:31:54.615262Z"
    }
   },
   "outputs": [],
   "source": [
    "y_forecast_preg = forecast_poly(last_conf_value, reg, 10, poly_features, scaler)\n",
    "y_forecast_preg.insert(0, last_conf_value[0,0])\n",
    "\n",
    "days_forecast_poly = np.arange(len(y_forecast_preg)) + days[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:54.894579Z",
     "start_time": "2020-05-23T19:31:54.627392Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "\n",
    "ax.plot(days,covid_worldwide['Confirmed'], label = \"Actual\")\n",
    "ax.plot(days_forecast_poly, y_forecast_preg, label = \"Forecast\")\n",
    "\n",
    "ax.set_title('Polynomial regression - forecasting the next {} days'.format(len(days_forecast_poly)-1))\n",
    "ax.set_xlabel(\"Day\")\n",
    "ax.set_ylabel(\"# of cases\")\n",
    "ax.legend(loc = 'best')\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [18, 12]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:54.946769Z",
     "start_time": "2020-05-23T19:31:54.896868Z"
    }
   },
   "outputs": [],
   "source": [
    "lasso_reg = Lasso()\n",
    "lasso_params = {'alpha':[0.01, 0.1, 1, 10], \n",
    "                'tol' : [1e-4, 1e-3, 1e-2], \n",
    "                'selection' : ['cyclic', 'random']\n",
    "               }\n",
    "\n",
    "cv = [(slice(None), slice(None))]\n",
    "\n",
    "gs_lasso = GridSearchCV(estimator=lasso_reg, param_grid=lasso_params, \n",
    "                  scoring=make_scorer(mean_squared_error, greater_is_better = False), cv=cv, n_jobs=-1)\n",
    "\n",
    "gs_lasso.fit(x_confirmed_train, y_confirmed_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:54.952619Z",
     "start_time": "2020-05-23T19:31:54.949180Z"
    }
   },
   "outputs": [],
   "source": [
    "gs_lasso.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:54.962238Z",
     "start_time": "2020-05-23T19:31:54.954932Z"
    }
   },
   "outputs": [],
   "source": [
    "lasso_reg_best = Lasso(alpha = 0.01, selection = 'cyclic', tol = 0.0001)\n",
    "lasso_reg_best.fit(x_confirmed_train, y_confirmed_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:54.970753Z",
     "start_time": "2020-05-23T19:31:54.964152Z"
    }
   },
   "outputs": [],
   "source": [
    "r2_training_lasso = lasso_reg_best.score(x_confirmed_train, y_confirmed_train)\n",
    "mse_training_lasso = mean_squared_error(y_confirmed_train, lasso_reg_best.predict(x_confirmed_train))\n",
    "r2_test_lasso = lasso_reg_best.score(x_confirmed_test, y_confirmed_test)\n",
    "mse_testing_lasso = mean_squared_error(y_confirmed_test, lasso_reg_best.predict(x_confirmed_test))\n",
    "print(r2_training_lasso,mse_training_lasso, r2_test_lasso, mse_testing_lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "  <tr>\n",
    "    <th></th>\n",
    "    <th scope=\"col\">MSE</th>\n",
    "    <th scope=\"col\">$R^2$</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th scope=\"row\">Training</th>\n",
    "    <td>422634914.04812187</td>\n",
    "    <td>0.999838</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th scope=\"row\">Testing</th>\n",
    "    <td>351981514.9093248</td>\n",
    "    <td>0.999847</td>\n",
    "  </tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forecast - LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:54.978211Z",
     "start_time": "2020-05-23T19:31:54.973520Z"
    }
   },
   "outputs": [],
   "source": [
    "y_forecast_lasso = forecast(last_conf_value, lasso_reg_best, 10, scaler)\n",
    "y_forecast_lasso.insert(0, last_conf_value[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:55.301290Z",
     "start_time": "2020-05-23T19:31:54.979800Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(days,covid_worldwide['Confirmed'], label = \"Actual\")\n",
    "ax.plot(days_forecast_poly, y_forecast_lasso, label = \"Forecast\")\n",
    "\n",
    "ax.set_title('LASSO - forecasting the next {} days'.format(len(days_forecast_poly)-1))\n",
    "ax.set_xlabel(\"Day\")\n",
    "ax.set_ylabel(\"# of cases\")\n",
    "ax.legend(loc = 'best')\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [18, 12]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:55.306671Z",
     "start_time": "2020-05-23T19:31:55.303697Z"
    }
   },
   "outputs": [],
   "source": [
    "x_confirmed_train_lstm = x_confirmed_train.reshape(x_confirmed_train.shape[0], 1, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:55.667576Z",
     "start_time": "2020-05-23T19:31:55.309295Z"
    }
   },
   "outputs": [],
   "source": [
    "model_lstm = Sequential([\n",
    "    LSTM(20, activation = 'relu', input_shape = (1,n), return_sequences = True),\n",
    "    LSTM(20, activation = 'relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "model_lstm.compile(optimizer = Adam(lr = 1.1), loss = 'mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:31:55.673510Z",
     "start_time": "2020-05-23T19:31:55.669554Z"
    }
   },
   "outputs": [],
   "source": [
    "model_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:32:03.164007Z",
     "start_time": "2020-05-23T19:31:55.675308Z"
    }
   },
   "outputs": [],
   "source": [
    "history = model_lstm.fit(x_confirmed_train_lstm, y_confirmed_train, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:32:03.168912Z",
     "start_time": "2020-05-23T19:32:03.166117Z"
    }
   },
   "outputs": [],
   "source": [
    "x_confirmed_test_lstm = x_confirmed_test.reshape(x_confirmed_test.shape[0], 1, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:32:03.850746Z",
     "start_time": "2020-05-23T19:32:03.170954Z"
    }
   },
   "outputs": [],
   "source": [
    "prediction_lstm = model_lstm.predict(x_confirmed_test_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:32:03.864788Z",
     "start_time": "2020-05-23T19:32:03.852806Z"
    }
   },
   "outputs": [],
   "source": [
    "r2_training_lstm = r2_score(y_confirmed_train, model_lstm.predict(x_confirmed_train_lstm))\n",
    "r2_test_lstm = r2_score(y_confirmed_test, prediction_lstm)\n",
    "mse_testing_lstm = mean_squared_error(y_confirmed_test, prediction_lstm)\n",
    "print(r2_training_lstm, r2_test_lstm, mse_testing_lstm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "  <tr>\n",
    "    <th></th>\n",
    "    <th scope=\"col\">MSE</th>\n",
    "    <th scope=\"col\">$R^2$</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th scope=\"row\">Training</th>\n",
    "    <td>407080714.6667</td>\n",
    "    <td>0.999837</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th scope=\"row\">Testing</th>\n",
    "    <td>359227875.00750625</td>\n",
    "    <td>0.999845</td>\n",
    "  </tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:32:03.893278Z",
     "start_time": "2020-05-23T19:32:03.867143Z"
    }
   },
   "outputs": [],
   "source": [
    "y_forecast_lstm = forecast_lstm(last_conf_value, model_lstm, 10, scaler)\n",
    "y_forecast_lstm.insert(0, last_conf_value[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:32:03.898720Z",
     "start_time": "2020-05-23T19:32:03.895117Z"
    }
   },
   "outputs": [],
   "source": [
    "y_forecast_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-23T19:32:04.189549Z",
     "start_time": "2020-05-23T19:32:03.900340Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(days,covid_worldwide['Confirmed'], label = \"Actual\")\n",
    "ax.plot(days_forecast_poly, y_forecast_lstm, label = \"Forecast\")\n",
    "\n",
    "ax.set_title('LSTM - forecasting the next {} days'.format(len(days_forecast_poly)-1))\n",
    "ax.set_xlabel(\"Day\")\n",
    "ax.set_ylabel(\"# of cases\")\n",
    "ax.legend(loc = 'best')\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [18, 12]\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
